{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import sqlite3\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "openai = OpenAI()\n",
    "\n",
    "DB = \"wiedza.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8aed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a technical assistant for residential construction knowledge.\n",
    "Answer questions using the provided database and tools whenever factual information is required.\n",
    "Give short, clear, and professional answers (maximum 5 sentences).\n",
    "Do not guess or invent information.\n",
    "If the database does not contain the answer, say explicitly that the information is not available.\n",
    "When numerical values or technical rules are mentioned, they must come from the database.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9209556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_information(query):\n",
    "    print(f\"DATABASE TOOL CALLED: Getting information for {query}\", flush=True)\n",
    "\n",
    "    q = (query or \"\").strip()\n",
    "    if not q:\n",
    "        return \"No query provided.\"\n",
    "\n",
    "    q_low = q.lower()\n",
    "\n",
    "    synonyms = {\n",
    "        \"electrical box\": \"puszka\",\n",
    "        \"electrical boxes\": \"puszka\",\n",
    "        \"electrical\": \"elektryka\",\n",
    "        \"spacing\": \"rozstaw\",\n",
    "        \"transport anchors\": \"haki transportowe\",\n",
    "        \"transport anchor\": \"hak transportowy\",\n",
    "        \"transport hooks\": \"haki transportowe\",\n",
    "        \"hooks\": \"haki\",\n",
    "        \"requirements\": \"wymagania\",\n",
    "    }\n",
    "    for k, v in synonyms.items():\n",
    "        q_low = q_low.replace(k, v)\n",
    "\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # 1) Komponenty\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            SELECT name, manufacturer, category, COALESCE(code,''), COALESCE(notes,'')\n",
    "            FROM component\n",
    "            WHERE lower(name) LIKE ? OR lower(COALESCE(code,'')) = ?\n",
    "            LIMIT 1\n",
    "            \"\"\",\n",
    "            (f\"%{q_low}%\", q_low)\n",
    "        )\n",
    "        comp = cursor.fetchone()\n",
    "        if comp:\n",
    "            name, manufacturer, category, code, notes = comp\n",
    "            code_part = f\", code: {code}\" if code else \"\"\n",
    "            return f\"{name} (category: {category}, manufacturer: {manufacturer}{code_part}). {notes}\".strip()\n",
    "\n",
    "        # 2) Chunks wiedzy\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            SELECT title, content, page_from\n",
    "            FROM knowledge_chunk\n",
    "            WHERE lower(title) LIKE ?\n",
    "               OR lower(content) LIKE ?\n",
    "               OR lower(COALESCE(tags,'')) LIKE ?\n",
    "               OR lower(COALESCE(site_scope,'')) LIKE ?\n",
    "            ORDER BY page_from\n",
    "            LIMIT 3\n",
    "            \"\"\",\n",
    "            (f\"%{q_low}%\", f\"%{q_low}%\", f\"%{q_low}%\", f\"%{q_low}%\")\n",
    "        )\n",
    "        chunks = cursor.fetchall()\n",
    "        if chunks:\n",
    "            return \"\\n\\n\".join([f\"{t} (p.{p}): {c}\" for (t, c, p) in chunks])\n",
    "\n",
    "        # 3) Liczby / rozstawy / odstępy (numeric_constraint)\n",
    "        if (\"rozstaw\" in q_low) or (\"odstęp\" in q_low) or (\"spacing\" in q.lower()):\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT kc.title, nc.subject, nc.operator, nc.value1, nc.value2, nc.unit, kc.page_from\n",
    "                FROM numeric_constraint nc\n",
    "                JOIN knowledge_chunk kc ON kc.chunk_id = nc.chunk_id\n",
    "                WHERE lower(nc.subject) LIKE ?\n",
    "                   OR lower(COALESCE(nc.context,'')) LIKE ?\n",
    "                ORDER BY kc.page_from\n",
    "                LIMIT 10\n",
    "                \"\"\",\n",
    "                (f\"%{q_low}%\", f\"%{q_low}%\")\n",
    "            )\n",
    "            rows = cursor.fetchall()\n",
    "            if rows:\n",
    "                lines = []\n",
    "                for title, subject, op, v1, v2, unit, page in rows:\n",
    "                    if op == \"between\" and v2 is not None:\n",
    "                        value_str = f\"{v1}–{v2}{unit}\"\n",
    "                    else:\n",
    "                        value_str = f\"{op} {v1}{unit}\"\n",
    "                    lines.append(f\"{title}: {subject} {value_str} (p.{page})\")\n",
    "                return \"\\n\".join(lines)\n",
    "\n",
    "    return \"No information available in the database.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_information(\"1264-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3533859",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_function = {\n",
    "    \"name\": \"get_information\",\n",
    "    \"description\": (\n",
    "        \"Retrieve technical information from the residential construction knowledge database. \"\n",
    "        \"Use this function to get factual data about construction components, rules, or standards.\"\n",
    "        \"The query may be in English, Polish, or German; the tool will normalize terms.\"\n",
    "    ),\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": (\n",
    "                    \"Name or code of a construction component (e.g. 'F92-3-452', 'Wellenanker'), \"\n",
    "                    \"or a technical topic (e.g. 'DB Fußanker M16', 'Elektryka').\"\n",
    "                )\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": information_function}]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a27aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL_GPT, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"get_information\":\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            query = arguments.get(\"query\")\n",
    "            if not query:\n",
    "                result = \"No query provided to get_information.\"\n",
    "            else:\n",
    "                result = get_information(query)\n",
    "\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": result\n",
    "            })\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses = handle_tool_calls(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "   \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(query):\n",
    "    image_response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=(\n",
    "            f\"Technical construction drawing of {query}. \"\n",
    "            f\"Clean line art, schematic style, neutral background, \"\n",
    "            f\"engineering illustration, no people, no text labels.\"\n",
    "        ),\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = artist(\"1264-60\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d09a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"gpt-4o-mini-tts\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy or coral\n",
    "      input=message\n",
    "    )\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fae36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls_and_return_queries(message):\n",
    "    responses = []\n",
    "    queries = []\n",
    "\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name != \"get_information\":\n",
    "            continue\n",
    "\n",
    "        # Bezpieczne parsowanie arguments\n",
    "        try:\n",
    "            arguments = json.loads(tool_call.function.arguments or \"{}\")\n",
    "        except json.JSONDecodeError:\n",
    "            arguments = {}\n",
    "\n",
    "        query = (arguments.get(\"query\") or \"\").strip()\n",
    "\n",
    "        if not query:\n",
    "            result = \"No query provided to get_information.\"\n",
    "        else:\n",
    "            result = get_information(query)\n",
    "\n",
    "            # Dodaj do queries tylko jeśli to wygląda jak temat do rysunku (a nie całe zdanie)\n",
    "            qlow = query.lower()\n",
    "            looks_like_component = (\n",
    "                re.search(r\"\\bf92-\\d-\\d+\\b\", qlow) is not None or\n",
    "                re.search(r\"\\b\\d{4}-\\d{2}\\b\", qlow) is not None or  # np. 1264-60\n",
    "                any(k in qlow for k in [\"fußanker\", \"fussanker\", \"wellenanker\", \"kaiser\", \"dbw\", \"dbf\"])\n",
    "            )\n",
    "            if looks_like_component:\n",
    "                queries.append(query)\n",
    "\n",
    "        responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": result\n",
    "        })\n",
    "\n",
    "    return responses, queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d241c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "\n",
    "    response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "\n",
    "    queries = []\n",
    "    image = None\n",
    "\n",
    "    max_loops = 5\n",
    "    loops = 0\n",
    "\n",
    "    while response.choices[0].finish_reason == \"tool_calls\" and loops < max_loops:\n",
    "        assistant_message = response.choices[0].message\n",
    "        tool_responses, new_queries = handle_tool_calls_and_return_queries(assistant_message)\n",
    "        queries.extend(new_queries or [])\n",
    "\n",
    "        messages.append(assistant_message)\n",
    "        messages.extend(tool_responses)\n",
    "\n",
    "        response = openai.chat.completions.create(model=MODEL_GPT, messages=messages, tools=tools)\n",
    "        loops += 1\n",
    "\n",
    "    reply = response.choices[0].message.content or \"\"\n",
    "    history = history + [{\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "    voice = talker(reply)\n",
    "\n",
    "    if queries:\n",
    "        image = artist(queries[0])\n",
    "\n",
    "    return history, voice, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b0eca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TOOL CALLED: Getting information for Wellenanker\n"
     ]
    }
   ],
   "source": [
    "def put_message_in_chatbot(message, history):\n",
    "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "\n",
    "# UI definition\n",
    "\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(autoplay=True)\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "\n",
    "# Hooking up events to callbacks\n",
    "\n",
    "\n",
    "    message.submit(put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, audio_output, image_output]\n",
    "    )\n",
    "\n",
    "\n",
    "ui.launch(inbrowser=True, auth=(\"ewelina\", \"wohnung\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
